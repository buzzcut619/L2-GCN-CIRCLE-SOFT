def convert_label_to_similarity(normed_feature: Tensor, label: Tensor) -> Tuple[Tensor, Tensor]:
    similarity_matrix = normed_feature @ normed_feature.transpose(1, 0)
    label_matrix = torch.matmul(label, label.T).clamp(max=1.0)
    label_matrix = label_matrix / label_matrix.sum(1, keepdim=True).clamp(min=1e-6)
    positive_matrix = label_matrix.triu(diagonal=1)
    negative_matrix = label_matrix.logical_not().triu(diagonal=1)
    positive_matrix = positive_matrix.int()
    negative_matrix = negative_matrix.int()
    similarity_matrix = similarity_matrix.view(-1)
    return similarity_matrix[positive_matrix], similarity_matrix[negative_matrix]

class CircleLoss(nn.Module):
    def __init__(self, m: float, gamma: float) -> None:
        super(CircleLoss, self).__init__()
        self.m = m
        self.gamma = gamma
        self.soft_plus = nn.Softplus()

    def forward(self, sp: Tensor, sn: Tensor) -> Tensor:
        ap = torch.clamp_min(- sp.detach() + 1 + self.m, min=0.)
        an = torch.clamp_min(sn.detach() + self.m, min=0.)

        delta_p = 1 - self.m
        delta_n = self.m

        logit_p = - ap * (sp - delta_p) * self.gamma
        logit_n = an * (sn - delta_n) * self.gamma

        loss = self.soft_plus(torch.logsumexp(logit_n, dim=0) + torch.logsumexp(logit_p, dim=0))

        return loss
def circleloss(view1_feature,view2_feature,labels):
    view1_feature = F.normalize(view1_feature, dim=1)
    view2_feature = F.normalize(view2_feature, dim=1)
    label_sim = torch.matmul(labels, labels.T).clamp(max=1.0)
    label_sim = label_sim / label_sim.sum(1, keepdim=True).clamp(min=1e-6)
    inpimg1,inpimg2=convert_label_to_similarity(view1_feature,label_sim)
    inptxt1,inptxt2=convert_label_to_similarity(view2_feature,label_sim)
    criterion = CircleLoss(m=0.25, gamma=16)
    circle_loss1 = criterion(inpimg1, inpimg2)
    circle_loss2 = criterion(inptxt1, inptxt2)
    circle_loss=torch.sum(circle_loss1+circle_loss2)
    return circle_loss

def soft_con_loss(view1_feature, view2_feature, labels, t=0.21, gamma=0.13):
    view1_feature = F.normalize(view1_feature, dim=1)
    view2_feature = F.normalize(view2_feature, dim=1)
    # cosine similarity: NxN
    sim_view12 = torch.matmul(view1_feature, view2_feature.T) / t
    sim_view11 = torch.matmul(view1_feature, view1_feature.T) / t
    sim_view22 = torch.matmul(view2_feature, view2_feature.T) / t
    #label_L1 = labels.sum(1)
    #label_sim = torch.matmul(labels, labels.T) / (label_L1[None, :] + label_L1[:, None] - torch.matmul(labels, labels.T))
    label_sim = torch.matmul(labels, labels.T).clamp(max=1.0)
    #label_sim = label_sim ** 0.5
    pro_inter = label_sim / label_sim.sum(1, keepdim=True).clamp(min=1e-6)
    label_sim_intra = (label_sim - torch.eye(label_sim.shape[0]).cuda()).clamp(min=0)
    pro_intra = label_sim_intra / label_sim_intra.sum(1, keepdim=True).clamp(min=1e-6)

    # logits: NxN
    logits_view12 = sim_view12 - torch.log(torch.exp(1.06 * sim_view12).sum(1, keepdim=True))
    logits_view21 = sim_view12.T - torch.log(torch.exp(1.06 * sim_view12.T).sum(1, keepdim=True))
    logits_view11 = sim_view11 - torch.log(torch.exp(1.06 * sim_view11).sum(1, keepdim=True))
    logits_view22 = sim_view22 - torch.log(torch.exp(1.06 * sim_view22).sum(1, keepdim=True))

    # compute mean of log-likelihood over positive
    mean_log_prob_pos_view12 = (pro_inter * logits_view12).sum(1)
    mean_log_prob_pos_view21 = (pro_inter * logits_view21).sum(1)
    mean_log_prob_pos_view11 = (pro_intra * logits_view11).sum(1)
    mean_log_prob_pos_view22 = (pro_intra * logits_view22).sum(1)

    # supervised cross-modal contrastive loss
    loss = - mean_log_prob_pos_view12.mean() - mean_log_prob_pos_view21.mean() \
           - gamma * (mean_log_prob_pos_view11.mean() + mean_log_prob_pos_view22.mean())

    return loss
